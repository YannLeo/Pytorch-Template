# A config file for DNN tests on MNIST dataset
#
# @Time    : 22/12/26 14:23
# @Author  : 
# @Notes   : Baseline tests. 
# 

name = 'mnist_fed_test'      # where to save the results under ./saved/
trainer = 'FedAvgTrainer' # the trainer name; main procedure

############################### Important hyper parameters!!
label_smoothing = 0.05


############################### Miscellaneous
epochs = 10
num_classes = 10
save_period = 5
# Whether to plot the confusion matrices in each test epoch to ./saved/**/confusion/*.jpg.
plot_confusion = true

############################### Fed
num_clients = 3
num_clients_select = 2
local_train_epoch = 1
local_train_step = -1

############################### Neural Networks
# The base model
[model]
name = 'SimpleCNN2D'
args = { num_classes = 10 }

############################### Dataloaders
# On source domian
[dataloader_train]
args = { batch_size = 128, num_workers = 2, shuffle = true, drop_last = false, pin_memory = true }
[dataloader_train.dataset]
name = "MNISTFedDataset"
args = { train = true, num_clients = 3 }
clients_args = {id = [0, 1, 2]}

[dataloader_test]
args = { batch_size = 128, num_workers = 2, shuffle = false, drop_last = false, pin_memory = true }
[dataloader_test.dataset]
name = "MNISTFedDataset"
args = { train = false, num_clients = 3 }
clients_args = {id = [0, 1, 2]}

############################### Learning Rate Schedulers for Optimizers
[lr_scheduler]
name = "StepLR"
init_lr = 0.0006
# args = { step_size = 600, gamma = 0.6 }
args = { epoch_size = 3.3, gamma = 0.6 } # epoch_size can be converted to step_size
